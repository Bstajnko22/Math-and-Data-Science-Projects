{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658c1924",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection with a Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75535887",
   "metadata": {},
   "source": [
    "This is a small addon project to another machine learning project I completed with standard classification models. \n",
    "\n",
    "By using tensorflow/keras I have created a simple neural network which takes 3 features from a credit card transaction dataset and classifies the transaction as fraudulent or not fraudulent.\n",
    "\n",
    "This sort of model could be very useful for banks for fraud prevention and minimisation as it would allow them to identify fraudulent transactions quickly. Which would then enable them to either reverse the transactions or freeze the card to prevent further spending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0019eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.set_printoptions(suppress = True) # Stopping scientific notation in numpy outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38048645",
   "metadata": {},
   "source": [
    "## Import the Data with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f83284",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_arr = np.genfromtxt(fname = r\"C:\\Users\\user1\\Documents\\Python Scripts\\archive(3)\\card_transdata.csv\", \n",
    "                           delimiter = \",\", \n",
    "                           skip_header = 1) # Skipping the column names as they'll just read NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e44593",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912bdfe",
   "metadata": {},
   "source": [
    "This dataset is already perfect, still some preprocessing needs to be done. Such as seperating the numerical and categorical features as well as feature scaling for the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5adb631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = credit_arr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e35c087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = data[:, :3] # Features, numerical and categorical.\n",
    "targets = data[:, -1] # Targets, categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83f4661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57.87785658,  0.31114001,  1.94593998],\n",
       "       [10.8299427 ,  0.1755915 ,  1.29421881],\n",
       "       [ 5.09107949,  0.80515259,  0.42771456],\n",
       "       ...,\n",
       "       [ 2.91485699,  1.47268669,  0.21807549],\n",
       "       [ 4.25872939,  0.24202337,  0.47582206],\n",
       "       [58.10812496,  0.31811012,  0.38691985]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29014a23",
   "metadata": {},
   "source": [
    "Column 1: Distance from Home\n",
    "\n",
    "Column 2: Distance from last Transaction\n",
    "\n",
    "Column 3: Ratio to Median Purchase Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64257a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ced1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled = scaler.transform(X = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d090d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00544291, 0.00002624, 0.00725   ],\n",
       "       [0.00101809, 0.00001481, 0.00481638],\n",
       "       [0.00047835, 0.00006793, 0.00158072],\n",
       "       ...,\n",
       "       [0.00027368, 0.00012426, 0.0007979 ],\n",
       "       [0.00040007, 0.00002041, 0.00176036],\n",
       "       [0.00546457, 0.00002683, 0.00142839]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ee0516",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features_scaled, targets, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0f8c7",
   "metadata": {},
   "source": [
    "## Constructing the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd192d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outputs = 2 # Rows in the output column vector (Yes/No).\n",
    "n_hidden1 = 10 # Number of nodes in layer 1.\n",
    "n_hidden2 = 10 # Number of nodes in layer 2.\n",
    "n_input = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c7bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model1 = keras.Sequential(layers = [keras.layers.Dense(units = n_hidden1, activation = \"relu\", input_dim = n_input), \n",
    "                                      keras.layers.Dense(units = n_hidden2, activation = \"relu\"), \n",
    "                                      keras.layers.Dense(units = n_outputs, activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6638f2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 172\n",
      "Trainable params: 172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55b666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model1.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ae328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.1647 - Accuracy: 0.9260\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.1355 - Accuracy: 0.9303\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.1311 - Accuracy: 0.9313\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.1225 - Accuracy: 0.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d7828924f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "\n",
    "NN_model1.fit(x = x_train, y = y_train, epochs = n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3abff8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76438046, 0.23561946],\n",
       "       [1.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = x_train[10:12, :] # Testing some predictings from the training set.\n",
    "\n",
    "NN_model1.predict(x = test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46865b",
   "metadata": {},
   "source": [
    "## On the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84136d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pred = NN_model1.predict(x = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9655489",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_predict_set = test_set_pred[:, 1]\n",
    "\n",
    "mapping_set = [0 if n < 0.5 else 1 for n in fraud_predict_set] # Taking the softmax output of the fraudulent output node and mapping the values to 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "653d6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final_predict = np.array(mapping_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20ed9837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score for this Neural Network model on the test set is: 0.936835\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(y_true = y_test, y_pred = y_final_predict)\n",
    "\n",
    "print(\"The accuracy score for this Neural Network model on the test set is: \" + str(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2e2b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_conf_mat = confusion_matrix(y_true = y_test, y_pred = y_final_predict) # Confusion matrix for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c58b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(true_pos, false_neg):\n",
    "    \"\"\"Takes the true positive and false negative number as inputs and returns the recall score of the model.\"\"\"\n",
    "    \n",
    "    rec_score = true_pos/(true_pos + false_neg)\n",
    "    \n",
    "    return rec_score\n",
    "\n",
    "def precision_score(true_pos, false_pos):\n",
    "    \"\"\"Takes the true positive and false positve number as input and returns the precision score of the model.\"\"\"\n",
    "    \n",
    "    prec_score = true_pos/(true_pos + false_pos)\n",
    "    \n",
    "    return prec_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3f1309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7113818823663384\n",
      "0.6228936085352478\n"
     ]
    }
   ],
   "source": [
    "TP = NN_conf_mat[1, 1] # True Positive.\n",
    "FN = NN_conf_mat[1, 0] # False Negative.\n",
    "FP = NN_conf_mat[0, 1] # False Positive.\n",
    "\n",
    "rec_score = recall_score(true_pos = TP, false_neg = FN)\n",
    "prec_score = precision_score(true_pos = TP, false_pos = FP)\n",
    "\n",
    "print(rec_score)\n",
    "print(prec_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f52b821",
   "metadata": {},
   "source": [
    "Higher recall score than precision score, in the context of credit fraud prevention I feel this is appropriate. This is because our main goal is to predict as many actually fraudulent transactions as possible in order minimize losses and consumer harm. If we have a lower precision (ie. predicting many transactions as fraudulent when a fair few aren't) then this doesnt matter so much as its only a slight nuisance to the consumer and can be fixed quickly with failsafes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2721ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(precision, recall):\n",
    "    \"\"\"Takes precision and recall values as inputs and returns the f1 score of the model.\"\"\"\n",
    "    \n",
    "    f1 = 2*((precision*recall)/(precision + recall))\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d833fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6642035033624838\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(precision = prec_score, recall = rec_score)\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedd9c8b",
   "metadata": {},
   "source": [
    "## Presenting Results\n",
    "\n",
    "As can be observed from the evaluation metrics, a simple neural network does offer strong predictive power for classifying credit card transactions as either fraudulent or not fraudulent. This predictive power may even offer an advantage over standard machine learning models. I know in some contexts neural networks are considered \"overkill\" however if a model like this can save a bank lots of money by accurately classifying fraud then implementing it could be quite useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
